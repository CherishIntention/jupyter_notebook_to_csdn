{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f5f598",
   "metadata": {},
   "source": [
    "### 模型参数的访问、初始化和共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a943cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd, init\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25498a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='relu'),\n",
    "       nn.Dense(10))\n",
    "net.initialize()  # 使用默认初始化方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6aea87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nd.random.uniform(shape=(2, 20))\n",
    "Y = net(X)  # 前向计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1e2f3",
   "metadata": {},
   "source": [
    "#### 对于使用Sequential类构造的神经网络，可以通过下标来访问网络中的任一层。通过Block类的params属性可以访问该层包含的所有参数，索引0表示Sequential实例最先添加的隐藏层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12f0a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dense0_ (\n",
       "   Parameter dense0_weight (shape=(256, 20), dtype=float32)\n",
       "   Parameter dense0_bias (shape=(256,), dtype=float32)\n",
       " ),\n",
       " mxnet.gluon.parameter.ParameterDict)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params, type(net[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c0ba2",
   "metadata": {},
   "source": [
    "#### 由上面的输出可以得知，它是一个由参数名映射到参数实例的字典（类型为ParameterDict类）。其中权重参数的名称为dense0_weight,它由net[0]的名称(dense0_)和自己的变量名(weight)组成。既可以使用名字来访问字典里面的元素，也可以直接使用它的变量名。通常后者的代码可读性更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23159f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter dense0_weight (shape=(256, 20), dtype=float32),\n",
       " Parameter dense0_weight (shape=(256, 20), dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params['dense0_weight'], net[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69f5fa",
   "metadata": {},
   "source": [
    "#### Gluon中参数类型为Parameter类，它包含参数和梯度的数值，可以分别通过data函数和grad函数来访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36366b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.06700657 -0.00369488  0.0418822  ... -0.05517294 -0.01194733\n",
       "  -0.00369594]\n",
       " [-0.03296221 -0.04391347  0.03839272 ...  0.05636378  0.02545484\n",
       "  -0.007007  ]\n",
       " [-0.0196689   0.01582889 -0.00881553 ...  0.01509629 -0.01908049\n",
       "  -0.02449339]\n",
       " ...\n",
       " [ 0.00010955  0.0439323  -0.04911506 ...  0.06975312  0.0449558\n",
       "  -0.03283203]\n",
       " [ 0.04106557  0.05671307 -0.00066976 ...  0.06387014 -0.01292654\n",
       "   0.00974177]\n",
       " [ 0.00297424 -0.0281784  -0.06881659 ... -0.04047417  0.00457048\n",
       "   0.05696651]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c3d8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " ...\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.grad()  # 由于没有进行反向传播计算，所以梯度的值全为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2360a64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 10 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].bias.data()  # 输出层的偏差值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49eab8",
   "metadata": {},
   "source": [
    "#### 使用collect_params函数获取net变量所有嵌套的层所包含的所有参数。返回的是一个由参数名称到参数实例的字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7224312d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter dense0_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense0_bias (shape=(256,), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(10, 256), dtype=float32)\n",
       "  Parameter dense1_bias (shape=(10,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04e715",
   "metadata": {},
   "source": [
    "#### 可以使用正则表达式匹配参数名，从而筛选出需要的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f2400c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter dense0_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(10, 256), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params('.*weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f937c",
   "metadata": {},
   "source": [
    "#### 初始化模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbeba7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 0.00195949 -0.0173764   0.00047347  0.00145809  0.00326049  0.00457878\n",
       " -0.00894258  0.00493839 -0.00904343 -0.01214079  0.02156406  0.01093822\n",
       "  0.01827143 -0.0104467   0.01006219  0.0051742  -0.00806932  0.01376901\n",
       "  0.00205885  0.00994352]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非首次初始化需要指定force_reinit为真\n",
    "net.initialize(init=init.Normal(sigma=0.01), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9d2c3",
   "metadata": {},
   "source": [
    "#### 使用常数来初始化权重参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94077f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize(init=init.Constant(1), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3e890",
   "metadata": {},
   "source": [
    "#### 如果只想对某个参数进行初始化，可以调用Parameter类的initialize函数，它与Block类的initialize函数用法一致。下面对隐藏层的权重参数使用Xavier随机初始化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c19e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 0.00512482 -0.06579044 -0.10849719 -0.09586414  0.06394844  0.06029618\n",
       " -0.03065033 -0.01086642  0.01929168  0.1003869  -0.09339568 -0.08703034\n",
       " -0.10472868 -0.09879824 -0.00352201 -0.11063069 -0.04257748  0.06548801\n",
       "  0.12987629 -0.13846186]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.initialize(init=init.Xavier(), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282daa8",
   "metadata": {},
   "source": [
    "#### 自定义初始化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fd689",
   "metadata": {},
   "source": [
    "#### 如果我们需要的初始化方法并没有在init模块中提供。这时，可以实现一个Initializer类的子类。通常，我们只需要实现_init_weight这个函数，并将传入的NDArray修改成初始化之后的结果。在下面的例子中，我们令权重有一半的概率初始化为0，另一半的概率初始化为[-10, -5]和[5, 10]两个去建立均匀分布的随机数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ceb6b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense0_weight (256, 20)\n",
      "Init dense1_weight (10, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[-5.3659673  7.5773945  8.986376  -0.         8.827555   0.\n",
       "  5.9840508 -0.         0.         0.         7.4857597 -0.\n",
       " -0.         6.8910007  6.9788704 -6.1131554  0.         5.4665203\n",
       " -9.735263   9.485172 ]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyInit(init.Initializer):\n",
    "    def _init_weight(self, name ,data):\n",
    "        print('Init', name, data.shape)\n",
    "        data[:] = nd.random.uniform(-10, 10, shape=data.shape)\n",
    "        data *= data.abs()>=5\n",
    "\n",
    "net.initialize(MyInit(), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0962a",
   "metadata": {},
   "source": [
    "#### 此外，还可以通过Parameter类的set_data函数直接改写模型参数。例如，在下例中我们将隐藏层参数在现有的基础上加1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bceee3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-4.3659673  8.5773945  9.986376   1.         9.827555   1.\n",
       "  6.9840508  1.         1.         1.         8.48576    1.\n",
       "  1.         7.8910007  7.9788704 -5.1131554  1.         6.4665203\n",
       " -8.735263  10.485172 ]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.set_data(net[0].weight.data() + 1)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e28f56",
   "metadata": {},
   "source": [
    "#### 共享模型参数。在下面的例子中，第二隐藏层（shared变量）和第三隐藏层共享模型参数。因为模型参数里包含了梯度，所以在反向传播计算时，第二隐藏层和第三隐藏层的梯度都会被累加在shared.params.grad()里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30706fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 8 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "shared = nn.Dense(8, activation='relu')\n",
    "net.add(nn.Dense(8, activation='relu'),\n",
    "       shared,\n",
    "       nn.Dense(8, activation='relu', params=shared.params),\n",
    "       nn.Dense(10))\n",
    "net.initialize()\n",
    "\n",
    "X = nd.random.uniform(shape=(2, 20))\n",
    "net(X)\n",
    "\n",
    "net[1].weight.data()[0] == net[2].weight.data()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_gluon",
   "language": "python",
   "name": "py36_gluon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
